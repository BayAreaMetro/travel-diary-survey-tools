---
title: "Work From Home Analysis - BATS 2023"
format:
  html:
    code-fold: true
    toc: true
    toc-depth: 3
jupyter: python3
---

# Overview

This report analyzes work-from-home (WFH) patterns among employed persons in the BATS 2023 survey data. The analysis examines:

-   Telework frequency (days per week working from home)
-   Commute frequency (days per week commuting to workplace)
-   Telework ratio (proportion of work days spent at home)
-   Temporal validation (identifying impossible telework/commute combinations)

## Setup

```{python}
#| label: imports

import logging
from enum import IntEnum
from pathlib import Path

import polars as pl
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

from pipeline.pipeline import Pipeline
from processing import link_trips, load_data, write_data
from processing.cleaning.clean_bats_2023 import clean_2023_bats
from data_canon.core.labeled_enum import LabeledEnum

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s",
)
logger = logging.getLogger(__name__)
```

```{python}
#| label: mount-drives
#| output: false

import os

# Try to mount network drives if not already mounted
try:
    os.system(r"net use M: \\models.ad.mtc.ca.gov\data\models")
    logger.info("Mounted M: drive")
except Exception as e:
    logger.warning(f"Could not mount M: drive: {e}")

try:
    os.system(r"net use X: \\model3-a\Model3A-Share")
    logger.info("Mounted X: drive")
except Exception as e:
    logger.warning(f"Could not mount X: drive: {e}")
```

## Run Pipeline

```{python}
#| label: constants

# Custom enums for categorizing responses
class FrequencyCategory(LabeledEnum):
    """Ordered frequency categories for sorting."""
    FIVE_PLUS = (5, "5+ days per week")
    FOUR = (4, "4 days per week")
    TWO_THREE = (3, "2-3 days per week")
    ONE = (2, "1 day per week")
    LESS_THAN_WEEKLY = (1, "Less than once a week")
    NEVER = (0, "Almost never")
    MISSING = (-1, "Missing Response")


class TeleworkRatio(LabeledEnum):
    """Ordered telework ratio categories for sorting."""
    ALWAYS = (4, "Always")
    MORE_THAN_60 = (3, "More than 60% of the time")
    ABOUT_HALF = (2, "About half (40-60%)")
    LESS_THAN_40 = (1, "Less than 40% of the time")
    NEVER = (0, "Never, or less than once a week")
    MISSING = (-1, "Missing Response")

# Employment codes we care about (from data_canon.codebook.persons.Employment)
EMPLOYED_CODES = [1]  # Fulltime employed persons only

# Configuration
CONFIG_PATH = Path("config.yaml")
CACHE_PATH = ".cache"
```

```{python}
#| label: load-data
#| output: false

# Load the 2019 and 2023 persons data
persons_23_dir = Path(
    "E:/Box/Modeling and Surveys/Surveys/Travel Diary Survey/BATS_2023/MTC_RSG_Partner Repository/"
    "5.Deliverables/Task 10 - Weighting and Expansion Data Files/UnweightedDataset/"
)
persons_19_dir = Path(
    "M:/Data/HomeInterview/Bay Area Travel Study 2018-2019/Data/Final Version with Imputations/"
    "Final Updated Dataset as of 10-18-2021/"
)
weights_23_dir = Path(
    "X:/survey_repos/ProjRoot_Mon-Thu20251201/WgtRoot_Mon-Thu20251201_nocommutemode/output/"
)
weights_23_path = Path(
    "X:/survey_repos/ProjRoot_Mon-Thu20251201/WgtRoot_Mon-Thu20251201_nocommutemode/output/"
    "person_weights.csv"
)

# Load the 2019 data
persons_19 = pl.read_csv(
    persons_19_dir / "person.tsv",
    separator="\t",
    ignore_errors=True,
)

# Load 2023 data and replace the old weights
weights_23 = pl.read_csv(weights_23_dir / "person_weights.csv")
persons_23 = pl.read_csv(persons_23_dir / "person.csv")
persons_23 = (
    persons_23.drop("person_weight")
    .join(
        weights_23.select("person_id", "person_weight"),
        on="person_id",
        how="left",
    )
)

```

## Data Preparation

### Telework frequency

The 2- and 3-day telework/commute frequencies are binned in 2019 and will need to be binned in 2023 for consistency.

| 2019 Code | Label                 | 2023 Code | Label                 |
|-----------|-----------------------|-----------|-----------------------|
| 1         | 6-7 Days a week       | 1         | 6-7 Days a week       |
| 2         | 5 Days a week         | 2         | 5 Days a week         |
| 3         | 4 Days a week         | 3         | 4 Days a week         |
| 4         | 2-3 Days a week       | 4         | 3 Days a week         |
| 4         | 2-3 Days a week       | 5         | 2 Days a week         |
| 5         | 1 Day a week          | 6         | 1 Day a week          |
| 6         | 1-3 days a month      | 7         | 1-3 days a month      |
| 7         | Less than monthly     | 8         | Less than monthly     |
| 8         | Never                 | 996       | Never                 |
| 995       | Missing               | 995       | Missing               |


```{python}
#| label: downcode-telework
#|

# Maps 2023 to 2019 codes for telework and commute freq
downcode_map = {
    1: 1,
    2: 2,
    3: 3,
    4: 4,
    5: 4,
    6: 5,
    7: 6,
    8: 7,
    996: 8,
    995: 995,
}

# Apply the downcoding to the 2023 data
persons_23 = persons_23.with_columns(
    # Copy original data
    telework_freq_original=pl.col("telework_freq"),
    commute_freq_original=pl.col("commute_freq"),
    # Apply downcoding
    telework_freq=pl.col("telework_freq").replace_strict(downcode_map),
    commute_freq=pl.col("commute_freq").replace_strict(downcode_map),
)

```

### Impute commute_freq
There is no `commute_freq` data in the 2019 survey, we will need to approximate days/week from `hours_work` minus `telework_hours` (assuming 8 hours is a typical workday).

```{python}
#| label: impute-commute-freq
#| output: false

# Hours vary greatly week to week
hours_work = {
    1: 55,
    2: 44,
    3: 36,
    4: 32,
    5: 24,
    6: 16,
    7: 8,
    8: None,
    995: None,
    -9998: None,
}

telework_hours = {
    1: 48,
    2: 40,
    3: 32,
    4: 16,
    5: 8,
    6: 0,
    7: 0,
    8: 0,
    996: 0,
    995: None,
}

commute_freq_map = {
    0: 8,
    1: 5,
    2: 4,
    3: 4,
    4: 3,
    5: 2,
    6: 1,
    7: 1,
    None: 995,
}

# Impute commute frequency for 2019 data
persons_19 = persons_19.with_columns(
    commute_freq_days=(
        (
            pl.col("hours_work").replace_strict(hours_work) -
            pl.col("telework_freq").replace_strict(telework_hours)
        ).clip(lower_bound=0)
    ) // 8,
)

# Map commute days to the 2019 frequency codes
persons_19 = persons_19.with_columns(
    commute_freq=pl.col("commute_freq_days").replace_strict(commute_freq_map),
)
# Rename person_weight_rmove_only to person_weight
persons_19 = persons_19.with_columns(
    person_weight=pl.col("wt_sphone_wkday"),
    job_type=pl.when(pl.col("job_type") == -9998).then(995).otherwise(pl.col("job_type")),
)

# Distribution of imputed commute freq
fig = px.histogram(
    persons_19.filter(pl.col("employment").is_in(EMPLOYED_CODES)),
    x="commute_freq_days",
    title="Distribution of Imputed Commute Frequency (2019)",
    labels={"commute_freq": "Days per week commuting to workplace"},
    nbins=10,
)
fig.update_layout(
    xaxis_title="Days per week commuting to workplace",
    yaxis_title="Number of persons",
    bargap=0.1,
)
fig.show()

persons_19.group_by("commute_freq").len()

```

### Data filtering

For `job_type==3` (WFH always), it is ambiguous to know if someone simply never commutes because they hardly work outside the home, or if they truly never commute. Therefore, for simplicity, we will narrow the analysis to only full-time employed persons.

```{python}
#| label: prepare-data

# Key columns to select
key_columns = [
    "person_id",
    "employment",
    "telework_freq",
    "commute_freq",
    "job_type",
    "person_weight",
]

# Combine the data
persons = pl.concat([
    persons_19.select(key_columns).with_columns(year=pl.lit(2019, pl.Utf8)),
    persons_23.select(key_columns).with_columns(year=pl.lit(2023, pl.Utf8)),
    ],
    rechunk=True
)

# Prepare person table
persons_clean = (
    # Drop rows with missing weights (incomplete days etc.)
    persons
    .filter(
        pl.col("person_weight").is_not_null()
        & (pl.col("person_weight") > 0)
    )
)

# Check person sum for reasonableness
person_weight_sum = persons_clean.select("person_weight").sum().item()
logger.info(f"Sum of person weights: {person_weight_sum:.2f}")

# Filter just employed persons
employed_persons = persons_clean.filter(
    # Must be employed AND not missing job type
    pl.col("employment").is_in(EMPLOYED_CODES) & (pl.col("job_type") != 995)
).select(
    "person_id",
    "employment",
    "telework_freq",
    "commute_freq",
    "job_type",
    "person_weight",
    "year",
)

logger.info(f"Total employed persons: {len(employed_persons):,}")
logger.info(f"Weighted employed persons: {employed_persons['person_weight'].sum():.0f}")
```

### Survey Code Reference

**Employment Codes:** - 1: Employed full-time (paid) - 2: Employed part-time (paid) - 3: Self-employed - 5: Not employed and not looking for work - 6: Unemployed and looking for work - 7: Unpaid volunteer or intern - 8: Employed, but not currently working - 995: Missing Response

**Telework/Commute Frequency Codes:** - 1: 6-7 days a week - 2: 5 days a week - 3: 4 days a week - 4: 3 days a week - 5: 2 days a week - 6: 1 day a week - 7: 1-3 days a month - 8: Less than monthly - 995: Missing Response - 996: Never

**Job Type Codes:** - 1: One work location - 2: Multiple work locations - 3: WFH always - 4: Travel for work - 5: Hybrid - 995: Missing Response

## Analysis

### Classification Rules

#### Telework / Commute Frequency Categorization
Simple definition of telework and commute frequency categorization.\
Mirrored for commute freq using commute_freq instead of telework_freq

| Days per Week Category | Telework Frequency Rules                          | Commute Frequency Rules                           |
|------------------------|---------------------------------------------------|---------------------------------------------------|
| 5+ days per week       | `telework_freq` in \[1, 2\] OR `job_type` == 3    | `commute_freq` in \[1, 2\] AND `job_type` != 3    |
| 4 days per week        | `telework_freq` == 3                              | `commute_freq` == 3                               |
| 2-3 days per week      | `telework_freq` == 4                              | `commute_freq` == 4                               |
| 1 day per week         | `telework_freq` == 5                              | `commute_freq` == 5                               |
| Less than once a week  | `telework_freq` in \[6, 7\]                       | `commute_freq` in \[6, 7\]                        |
| Never                  | `telework_freq` == 8                              | `commute_freq` == 8                               |
| Missing Response       | `telework_freq` == 995 AND `job_type` != 3        | `commute_freq` == 995 AND `job_type` != 3         |


#### Telework Ratio Categorization

While more broad, this categorization accounts for part-time or over-time work scenarios (<5 and >5 days/week).

| Telework Ratio Category           | Rules                                                                                                 |
|-----------------------------------|-----------------------------------------------------------------------------------------------|
| Never, or less than once a week   | `telework_freq` in [995, 6, 7, 8] AND `job_type` != 3                                               |
| Less than 40% of the time         | `telework_freq` > `commute_freq` + 1 AND both < 7 (weekly+) AND both != 995 AND `job_type` != 3       |
| About half (40-60%)               | \|`telework_freq` - `commute_freq`\| ≤ 1 AND both < 7 (weekly+) AND both != 995 AND `job_type` != 3   |
| More than 60% of the time         | `commute_freq` > `telework_freq` + 1 AND both < 7 (weekly+) AND both != 995 AND `job_type` != 3       |
| Always                            | (`telework_freq` in [1, 2] AND `commute_freq` == 8) OR `job_type` == 3                              |

#### Categorization Function
```{python}
#| label: categorization-function
#| output: false

def categorize_frequency(
    df: pl.DataFrame,
    prefix: str,
    conditions: dict[str, pl.Expr],
) -> pl.DataFrame:
    """
    Categorize frequency data using one-hot encoding with validation.

    Args:
        df: Input dataframe
        prefix: Prefix for output columns (e.g., 'telework_freq' or 'commute_freq')
        conditions: Dictionary of labeled conditions and expressions to categorize by

    Returns:
        DataFrame with unpivoted frequency categories
    """
    # Create one-hot encoded columns
    one_hot_exprs = []
    one_hot_cols = []

    for category in conditions.keys():
        col_name = category.name.lower()
        one_hot_cols.append(col_name)

        # Build condition based on category
        condition = conditions.get(category, None)

        if condition is None:
            raise ValueError(f"Unknown category: {category}")

        one_hot_exprs.append(
            condition.cast(pl.Int8).alias(col_name)
        )

    # Add one-hot columns
    df_one_hot = df.with_columns(one_hot_exprs)

    # Verify mutual exclusivity
    count_col = "category_count"
    df_one_hot = df_one_hot.with_columns(
        pl.sum_horizontal(one_hot_cols).alias(count_col)
    )

    # Check for violations
    violations = df_one_hot.filter(pl.col(count_col) != 1)

    if len(violations) > 0:
        chk_cols = ["person_id", "telework_freq", "commute_freq", "job_type", count_col] + one_hot_cols

        # If _freq_cat cols are in the table
        for c in ["telework_freq_cat", "commute_freq_cat"]:
            if c in df_one_hot.columns:
                chk_cols.append(c)

        logger.warning(
            f"Found {len(violations)} persons with non-exclusive {prefix} categories!"
        )
        print(f"\n{prefix.upper()} Category Violations:")
        print(violations.select(chk_cols).head(10))
        raise ValueError(f"Found persons with non-exclusive {prefix} categories!")
    else:
        logger.info(f"✓ All persons have exactly 1 {prefix} category")

    # Unpivot to single column
    df_unpivot = (
        df_one_hot
        .unpivot(
            index="person_id",
            on=one_hot_cols,
            variable_name="category",
        )
        # Keep only rows where this category is true (value = 1)
        .filter(pl.col("value") > 0)
        # Map short names to enum values
        .with_columns(
            pl.col("category")
                .str.replace(f"{prefix}_", "")
                .str.to_uppercase()
                .replace({cat.name: cat.value for cat in conditions.keys()})
                .cast(pl.Int8)
                .alias(f"{prefix}_cat")
        )
        # Add descriptive labels
        .with_columns(
            pl.col(f"{prefix}_cat").cast(pl.Utf8)
            .replace({cat.value: cat.label for cat in conditions.keys()})
            .alias(f"{prefix}_str")
        )
        .drop("category", "value")
    )

    # Join back to employed persons
    join_cols = [
        f"{prefix}_str",
        f"{prefix}_cat"
     ]
    for col in join_cols:
        if col in df.columns:
            df = df.drop(col)

    df_joined = df.join(
        df_unpivot.select(["person_id"] + join_cols),
        on="person_id",
        how="left",
    )

    return df_joined

```

### Temporal Validation

Check for impossible combinations where telework + commute frequency exceeds 7 days/week.

```{python}
#| label: temporal-violations

# Check for temporal violations:
# Bad telework/commute freq combos where sum < 7 days/week
# ignoring the less than weekly and never categories
bad_freqs = employed_persons.filter(
    (pl.col("telework_freq") + pl.col("commute_freq") < 7)
    & (pl.col("telework_freq") < 8)
    & (pl.col("commute_freq") < 8)
)

bad_freqs_summary = pl.DataFrame(
    {
        "Count": [len(bad_freqs)],
        "Weighted count": [round(bad_freqs["person_weight"].sum(), 2)],
        "% (wtd)": [
            round(
                100
                * bad_freqs["person_weight"].sum()
                / employed_persons["person_weight"].sum(),
                2,
            )
        ],"% (unwtd)": [
            round(100 * bad_freqs.shape[0] / employed_persons.shape[0], 2),
        ],
    }
)
print("Temporal Violations Summary:")
print(bad_freqs_summary)
```

So about {python} f"{bad_freqs_summary['% (wtd)'].item():.2f}%" ` of the total weighted count of employed persons have impossible telework/commute frequency combinations. This is a relatively small proportion, but noticeable. The importance of this is that the following telework/commute frequency categories treat these as independent, which means these persons may be double counted in the analysis.


### Categorize Telework Frequency
```{python}
#| label: categorize-telework
telework_conditions = {
    # Works 5+ or always WFH
    FrequencyCategory.FIVE_PLUS: (
        pl.col("telework_freq").is_in([1, 2])
        | (pl.col("job_type") == 3)
    ),
    # Works 4 days
    FrequencyCategory.FOUR: (pl.col("telework_freq") == 3),
    # Works 2-3 days
    FrequencyCategory.TWO_THREE: (pl.col("telework_freq") == 4),
    # Works 1 day
    FrequencyCategory.ONE: (pl.col("telework_freq") == 5),
    # Less than weekly
    FrequencyCategory.LESS_THAN_WEEKLY: (pl.col("telework_freq").is_in([6, 7])),
    # Never
    FrequencyCategory.NEVER: (pl.col("telework_freq") == 8),
    # Missing
    FrequencyCategory.MISSING: (
        (pl.col("telework_freq") == 995)
        & (pl.col("job_type") != 3)
    ),
}

# Categorize telework frequency
employed_persons = categorize_frequency(
    employed_persons,
    prefix="telework_freq",
    conditions=telework_conditions,
)
```

### Categorize Commute Frequency

```{python}
#| label: categorize-commute
commute_conditions = {
    # Works 5+ days
    FrequencyCategory.FIVE_PLUS: (
        pl.col("commute_freq").is_in([1, 2])
        & (pl.col("job_type") != 3)
    ),
    # Works 4 days
    FrequencyCategory.FOUR: (pl.col("commute_freq") == 3),
    # Works 2-3 days
    FrequencyCategory.TWO_THREE: (pl.col("commute_freq") == 4),
    # Works 1 day
    FrequencyCategory.ONE: (pl.col("commute_freq") == 5),
    # Less than weekly
    FrequencyCategory.LESS_THAN_WEEKLY: (pl.col("commute_freq").is_in([6, 7])),
    # Never
    FrequencyCategory.NEVER: (
        # WFH Always
        (pl.col("job_type") == 3)
        # Never commutes
        | (pl.col("commute_freq") == 8)
    ),
    # Missing
    FrequencyCategory.MISSING: (
        (pl.col("commute_freq") == 995) &
        (pl.col("job_type") != 3)
    )
}

# Categorize commute frequency
employed_persons = categorize_frequency(
    employed_persons,
    prefix="commute_freq",
    conditions=commute_conditions,
)

```

### Calculate Telework Ratio
```{python}
#| label: telework-ratio

ratio_conditions = {
    # MISSING: Catch missing values first
    TeleworkRatio.MISSING: (
        (pl.col("telework_freq_cat") == FrequencyCategory.MISSING.value)
        | (pl.col("commute_freq_cat") == FrequencyCategory.MISSING.value)
    ),
    # ALWAYS: job_type==3 OR high telework with no/rare commute
    TeleworkRatio.ALWAYS: (
        (pl.col("telework_freq_cat").is_in([
            FrequencyCategory.FIVE_PLUS.value,
            FrequencyCategory.FOUR.value
        ])
        & pl.col("commute_freq_cat").is_in([
            FrequencyCategory.NEVER.value,
            FrequencyCategory.LESS_THAN_WEEKLY.value,
        ]))
        | (pl.col("job_type") == 3)
    ),
    # NEVER: telework is never/rare (not based on commute frequency)
    TeleworkRatio.NEVER: (
        pl.col("telework_freq_cat").is_in([
            FrequencyCategory.NEVER.value,
            FrequencyCategory.LESS_THAN_WEEKLY.value,
        ])
        & (pl.col("job_type") != 3)
        & (pl.col("telework_freq_cat") != FrequencyCategory.MISSING.value)
        & (pl.col("commute_freq_cat") != FrequencyCategory.MISSING.value)
    ),
    # LESS_THAN_40: commute significantly more than telework
    TeleworkRatio.LESS_THAN_40: (
        (pl.col("commute_freq_cat") > pl.col("telework_freq_cat") + 1) # +1 to get 40% threshold
        & (pl.col("telework_freq_cat") != FrequencyCategory.MISSING.value)
        & (pl.col("commute_freq_cat") != FrequencyCategory.MISSING.value)
        & (pl.col("job_type") != 3)
        # Exclude never/rare telework (handled by NEVER category)
        & ~pl.col("telework_freq_cat").is_in([
            FrequencyCategory.NEVER.value,
            FrequencyCategory.LESS_THAN_WEEKLY.value,
        ])
        # Exclude high telework with no/rare commute (handled by ALWAYS)
        & ~(
            pl.col("telework_freq_cat").is_in([
                FrequencyCategory.FIVE_PLUS.value,
                FrequencyCategory.FOUR.value
            ])
            & pl.col("commute_freq_cat").is_in([
                FrequencyCategory.NEVER.value,
                FrequencyCategory.LESS_THAN_WEEKLY.value,
            ])
        )
    ),
    # ABOUT_HALF: telework and commute roughly equal
    TeleworkRatio.ABOUT_HALF: (
        ((pl.col("telework_freq_cat") - pl.col("commute_freq_cat")).abs() <= 1) # 1 to get 40-60% threshold
        & (pl.col("telework_freq_cat") != FrequencyCategory.MISSING.value)
        & (pl.col("commute_freq_cat") != FrequencyCategory.MISSING.value)
        & (pl.col("job_type") != 3)
        # Exclude never/rare telework (handled by NEVER category)
        & ~pl.col("telework_freq_cat").is_in([
            FrequencyCategory.NEVER.value,
            FrequencyCategory.LESS_THAN_WEEKLY.value,
        ])
        # Exclude high telework with no/rare commute (handled by ALWAYS)
        & ~(
            pl.col("telework_freq_cat").is_in([
                FrequencyCategory.FIVE_PLUS.value,
                FrequencyCategory.FOUR.value
            ])
            & pl.col("commute_freq_cat").is_in([
                FrequencyCategory.NEVER.value,
                FrequencyCategory.LESS_THAN_WEEKLY.value,
            ])
        )
    ),
    # MORE_THAN_60: telework significantly more than commute
    TeleworkRatio.MORE_THAN_60: (
        (pl.col("telework_freq_cat") > pl.col("commute_freq_cat") + 1) # +1 to get 60% threshold
        & (pl.col("telework_freq_cat") != FrequencyCategory.MISSING.value)
        & (pl.col("commute_freq_cat") != FrequencyCategory.MISSING.value)
        & (pl.col("job_type") != 3)
        # Exclude never/rare telework (handled by NEVER category)
        & ~pl.col("telework_freq_cat").is_in([
            FrequencyCategory.NEVER.value,
            FrequencyCategory.LESS_THAN_WEEKLY.value,
        ])
        # Exclude high telework with no/rare commute (handled by ALWAYS)
        & ~(
            pl.col("telework_freq_cat").is_in([
                FrequencyCategory.FIVE_PLUS.value,
                FrequencyCategory.FOUR.value
            ])
            & pl.col("commute_freq_cat").is_in([
                FrequencyCategory.NEVER.value,
                FrequencyCategory.LESS_THAN_WEEKLY.value,
            ])
        )
    ),
}

# Categorize telework ratio
employed_persons = employed_persons_ratio = categorize_frequency(
    employed_persons,
    prefix="telework_ratio",
    conditions=ratio_conditions,
)
```

## Results

### Telework Frequency Distribution

```{python}
#| label: telework-freq-summary

telework_freq_summary = (
    employed_persons.group_by("year", "telework_freq_str", "telework_freq_cat")
    .agg(
        pl.len().alias("count"),
        pl.col("person_weight").sum().alias("weighted_count"),
    )
    .with_columns(
        (
            100 * pl.col("weighted_count") / pl.col("weighted_count").sum().over("year")
        ).alias("% (wtd)"),
        (100 * pl.col("count") / pl.col("count").sum().over("year")).alias("% (unwtd)"),
    )
    .with_columns(
        pl.col("weighted_count").round(2),
        pl.col("% (wtd)").round(2),
        pl.col("% (unwtd)").round(2),
    )
    .sort("telework_freq_cat")
)

print("Telework Frequency Summary - 2019:")
print(telework_freq_summary.filter(pl.col("year") == "2019").drop("telework_freq_cat"))
print("Telework Frequency Summary - 2023:")
print(telework_freq_summary.filter(pl.col("year") == "2023").drop("telework_freq_cat"))

```

### Commute Frequency Distribution

```{python}
#| label: commute-freq-summary

commute_freq_summary = (
    employed_persons.group_by("year", "commute_freq_str", "commute_freq_cat")
    .agg(
        pl.len().alias("count"),
        pl.col("person_weight").sum().alias("weighted_count"),
    )
    .with_columns(
        (
            100 * pl.col("weighted_count") / pl.col("weighted_count").sum().over("year")
        ).alias("% (wtd)"),
        (100 * pl.col("count") / pl.col("count").sum().over("year")).alias("% (unwtd)"),
    )
    .with_columns(
        pl.col("weighted_count").round(2),
        pl.col("% (wtd)").round(2),
        pl.col("% (unwtd)").round(2),
    )
    .sort("commute_freq_cat")
)
print("Commute Frequency Summary - 2019:")
print(commute_freq_summary.filter(pl.col("year") == "2019").drop("commute_freq_cat"))
print("Commute Frequency Summary - 2023:")
print(commute_freq_summary.filter(pl.col("year") == "2023").drop("commute_freq_cat"))

```

### Combined Telework and Commute Frequency Distribution

```{python}
#| label: fig-freq-shift-plot
#| fig-cap: "Shift in Telework and Commute Frequency: 2019 vs 2023"
# Create simple shift plots
# Create color mapping for consistent colors across both plots
import plotly.express as px

# Create graduated color scale
colors = px.colors.sample_colorscale(
    px.colors.sequential.Bluered,
    [0, 0.2, 0.4, 0.6, 0.8, 1.0]
)

color_map = {
    FrequencyCategory.FIVE_PLUS.label: colors[0],
    FrequencyCategory.FOUR.label: colors[1],
    FrequencyCategory.TWO_THREE.label: colors[2],
    FrequencyCategory.ONE.label: colors[3],
    FrequencyCategory.LESS_THAN_WEEKLY.label: colors[4],
    FrequencyCategory.NEVER.label: colors[5],
}

fig = make_subplots(rows=1, cols=2, subplot_titles=("Telework Frequency", "Commute Frequency"))

# Telework data
telework_pivot = (
    telework_freq_summary
    .filter(pl.col("telework_freq_str") != "Missing Response")
    .pivot(index=["telework_freq_str", "telework_freq_cat"], on="year", values="% (wtd)")
    .sort("telework_freq_cat", descending=True)
)

for row in telework_pivot.iter_rows(named=True):
    fig.add_trace(
        go.Scatter(
            x=[2019, 2023],
            y=[row["2019"], row["2023"]],
            mode='lines+markers',
            name=row["telework_freq_str"],
            line=dict(color=color_map.get(row["telework_freq_str"])),
            marker=dict(color=color_map.get(row["telework_freq_str"])),
        ),
        row=1, col=1
    )

# Commute data
commute_pivot = (
    commute_freq_summary
    .filter(pl.col("commute_freq_str") != "Missing Response")
    .pivot(index=["commute_freq_str", "commute_freq_cat"], on="year", values="% (wtd)")
    .sort("commute_freq_cat", descending=True)
)

for row in commute_pivot.iter_rows(named=True):
    fig.add_trace(
        go.Scatter(
            x=[2019, 2023],
            y=[row["2019"], row["2023"]],
            mode='lines+markers',
            name=row["commute_freq_str"],
            line=dict(color=color_map.get(row["commute_freq_str"])),
            marker=dict(color=color_map.get(row["commute_freq_str"])),
            showlegend=False,
        ),
        row=1, col=2
    )

# Find max value across both datasets to set matching y-axis range
max_val = max_val = max(
    telework_pivot['2019'].max(),
    telework_pivot['2023'].max(),
    commute_pivot['2019'].max(),
    commute_pivot['2023'].max(),
)

fig.update_xaxes(tickvals=[2019, 2023])
fig.update_yaxes(title_text="% (Weighted)", range=[0, max_val * 1.1])
fig.update_layout(height=500, title_text="Work Pattern Changes: 2019 to 2023")
fig.show()
```

### Telework Ratio (Proportion of Work Days at Home)

```{python}
#| label: telework-ratio-summary

telework_ratio_summary = (
    employed_persons.group_by("year", "telework_ratio_str", "telework_ratio_cat")
    .agg(
        pl.len().alias("count"),
        pl.col("person_weight").sum().alias("weighted_count"),
    )
    .with_columns(
        (
            100 * pl.col("weighted_count") / pl.col("weighted_count").sum().over("year")
        ).alias("% (wtd)"),
        (100 * pl.col("count") / pl.col("count").sum().over("year")).alias("% (unwtd)"),
    )
    .with_columns(
        pl.col("weighted_count").round(2),
        pl.col("% (wtd)").round(2),
        pl.col("% (unwtd)").round(2),
    )
    .sort("telework_ratio_cat")
    .drop("telework_ratio_cat")
)

print("Telework Ratio Summary - 2019:")
print(telework_ratio_summary.filter(pl.col("year") == "2019"))
print("Telework Ratio Summary - 2023:")
print(telework_ratio_summary.filter(pl.col("year") == "2023"))
```

```{python}
#| label: fig-telework-ratio
#| fig-cap: "Telework Ratio Distribution (Weighted)"
fig = px.bar(
    telework_ratio_summary,
    x="telework_ratio_str",
    y="% (wtd)",
    color="year",
    barmode="group",
    title="Proportion of Work Days Spent Working From Home by Survey Year",
    labels={"telework_ratio_str": "Telework Ratio", "% (wtd)": "Percentage (Weighted)", "year": "Survey Year"},
    text="% (wtd)",
)
fig.update_traces(texttemplate='%{text:.1f}%', textposition='outside')
fig.show()
```


## Summary

```{python}

# Define metric categories based on frequency
is_5plus = pl.col("telework_freq_cat") > FrequencyCategory.FOUR.value
is_2plus = pl.col("telework_freq_cat") >= FrequencyCategory.TWO_THREE.value
is_1orless = (
    (pl.col("telework_freq_cat") <= FrequencyCategory.ONE.value)
    & (pl.col("telework_freq_cat") != FrequencyCategory.MISSING.value)
)

# Categorize and aggregate in one chain
telework_metrics = (
    telework_freq_summary
    .with_columns(
        pl.when(is_5plus).then(pl.lit("5+ days per week"))
        .when(is_2plus).then(pl.lit("2+ days per week"))
        .when(is_1orless).then(pl.lit("1 day or less per week"))
        .alias("Telework Frequency")
    )
    .filter(pl.col("Telework Frequency").is_not_null())
    .group_by("year", "Telework Frequency")
    .agg(pl.col("% (wtd)").sum())
    .pivot(index="Telework Frequency", on="year", values="% (wtd)")
).sort("Telework Frequency").select(
    "Telework Frequency",
    "2019",
    "2023",
).with_columns(
    pl.col("2019").round(2).alias("2019 (%)"),
    pl.col("2023").round(2).alias("2023 (%)"),
)

# column sums

telework_metrics
# print("Summary of Key Telework Metrics:")
# print(f"Proportion of employed persons teleworking 5+ days/week:")
# for year, pct in telework_5plus.items():
#     print(f"  {year}: {pct:.2f}%")

# print(f"Proportion of employed persons teleworking 2+ days/week:")
# for year, pct in telework_2plus.items():
#     print(f"  {year}: {pct:.2f}%")

```
